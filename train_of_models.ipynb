{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this file we are going to train our four models with different combinations of preprocessing methods and vectorization methods for each model, so we can find out which combination of preprocessing and vectorization methods suits better for every type of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports \n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from config import path_to_data_folder\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "from functions_vectorization import TfidfVectorizer, CountVectorizer, Word2VecVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD THE MODELS\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\") # model trained on lower case words, use lower case tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load, clean, split the data on which we are going to train the pipeline and evaluate\n",
    "#### Create different pipelines for future model training, testing, evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\") # model trained on lower case words, use lower case tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_df_preprocessed_0 TfidfVectorizer RandomForestClassifier finished and stored\n",
      "gender_df_preprocessed_1 TfidfVectorizer RandomForestClassifier finished and stored\n",
      "gender_df_preprocessed_2 TfidfVectorizer RandomForestClassifier finished and stored\n",
      "gender_df_preprocessed_3 TfidfVectorizer RandomForestClassifier finished and stored\n",
      "gender_df_preprocessed_4 TfidfVectorizer RandomForestClassifier finished and stored\n",
      "gender_df_preprocessed_5 TfidfVectorizer RandomForestClassifier finished and stored\n",
      "gender_df_preprocessed_6 TfidfVectorizer RandomForestClassifier finished and stored\n",
      "gender_df_preprocessed_7 TfidfVectorizer RandomForestClassifier finished and stored\n",
      "gender_df_preprocessed_9 TfidfVectorizer RandomForestClassifier finished and stored\n",
      "gender_df_preprocessed_10 TfidfVectorizer RandomForestClassifier finished and stored\n",
      "gender_df_preprocessed_11 TfidfVectorizer RandomForestClassifier finished and stored\n",
      "gender_df_preprocessed_12 TfidfVectorizer RandomForestClassifier finished and stored\n",
      "gender_df_preprocessed_13 TfidfVectorizer RandomForestClassifier finished and stored\n",
      "gender_df_preprocessed_14 TfidfVectorizer RandomForestClassifier finished and stored\n",
      "gender_df_preprocessed_15 TfidfVectorizer RandomForestClassifier finished and stored\n",
      "gender_df_preprocessed_16 TfidfVectorizer RandomForestClassifier finished and stored\n",
      "gender_df_preprocessed_17 TfidfVectorizer RandomForestClassifier finished and stored\n",
      "gender_df_preprocessed_0 TfidfVectorizer LogisticRegression finished and stored\n",
      "gender_df_preprocessed_1 TfidfVectorizer LogisticRegression finished and stored\n",
      "gender_df_preprocessed_2 TfidfVectorizer LogisticRegression finished and stored\n",
      "gender_df_preprocessed_3 TfidfVectorizer LogisticRegression finished and stored\n",
      "gender_df_preprocessed_4 TfidfVectorizer LogisticRegression finished and stored\n",
      "gender_df_preprocessed_5 TfidfVectorizer LogisticRegression finished and stored\n",
      "gender_df_preprocessed_6 TfidfVectorizer LogisticRegression finished and stored\n",
      "gender_df_preprocessed_7 TfidfVectorizer LogisticRegression finished and stored\n",
      "gender_df_preprocessed_9 TfidfVectorizer LogisticRegression finished and stored\n",
      "gender_df_preprocessed_10 TfidfVectorizer LogisticRegression finished and stored\n",
      "gender_df_preprocessed_11 TfidfVectorizer LogisticRegression finished and stored\n",
      "gender_df_preprocessed_12 TfidfVectorizer LogisticRegression finished and stored\n",
      "gender_df_preprocessed_13 TfidfVectorizer LogisticRegression finished and stored\n",
      "gender_df_preprocessed_14 TfidfVectorizer LogisticRegression finished and stored\n",
      "gender_df_preprocessed_15 TfidfVectorizer LogisticRegression finished and stored\n",
      "gender_df_preprocessed_16 TfidfVectorizer LogisticRegression finished and stored\n",
      "gender_df_preprocessed_17 TfidfVectorizer LogisticRegression finished and stored\n"
     ]
    }
   ],
   "source": [
    "list_of_preprocessed_data = ['gender_df_preprocessed_0', 'gender_df_preprocessed_1', \"gender_df_preprocessed_2\", 'gender_df_preprocessed_3', 'gender_df_preprocessed_4', 'gender_df_preprocessed_5', 'gender_df_preprocessed_6', 'gender_df_preprocessed_7', 'gender_df_preprocessed_9', 'gender_df_preprocessed_10', 'gender_df_preprocessed_11', 'gender_df_preprocessed_12', 'gender_df_preprocessed_13', 'gender_df_preprocessed_14', 'gender_df_preprocessed_15', 'gender_df_preprocessed_16', 'gender_df_preprocessed_17']\n",
    "list_of_vectorizers = [TfidfVectorizer]\n",
    "list_of_models = [RandomForestClassifier, LogisticRegression]\n",
    "\n",
    "\n",
    "# PIPELINES COBINATION AND IT'S SCORES FOR GENDER DATA\n",
    "df = pd.read_csv('scores.csv', header=None, names=['pipeline_name', 'pipeline_scores'])\n",
    "\n",
    "# Extract the pipeline names\n",
    "finished_ = df['pipeline_name'].tolist()\n",
    "\n",
    "file_path = \"scores.csv\"\n",
    "for model in list_of_models:\n",
    "    for vectorizer in list_of_vectorizers:\n",
    "        for preprocessed_data in list_of_preprocessed_data:\n",
    "\n",
    "            pipeline_name = f\"pipeline_{preprocessed_data}_{vectorizer.__name__}_{model.__name__}\"\n",
    "\n",
    "            if pipeline_name not in finished_:\n",
    "                pipeline = Pipeline([\n",
    "                                    ('vectorizer', vectorizer()),\n",
    "                                    ('model', model())\n",
    "                                    ])\n",
    "\n",
    "                df = pd.read_json(f'{path_to_data_folder}/{preprocessed_data}.json')\n",
    "\n",
    "                X = df[f'post'].tolist()\n",
    "                y = df[f'female'].tolist()\n",
    "\n",
    "                # Split the dataset into training and testing sets\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "                # fi the pipe\n",
    "                pipeline.fit(X_train, y_train)\n",
    "\n",
    "                # Predict on the test set\n",
    "                y_pred = pipeline.predict(X_test)\n",
    "\n",
    "                y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "                input_in_the_file = [pipeline_name, [f'Score: {pipeline.score(X_test, y_test)}', f'precision: {precision_score(y_test, y_pred)}', f'Recall: {recall_score(y_test, y_pred)}', f'ROC AUC: {roc_auc_score(y_test, y_pred_proba)}']]\n",
    "\n",
    "                # Append new data to the CSV file\n",
    "                with open(file_path, 'a', newline='') as csv_file:\n",
    "                    csv_writer = csv.writer(csv_file)\n",
    "                    csv_writer.writerow(input_in_the_file)\n",
    "\n",
    "                print(f'{preprocessed_data} {vectorizer.__name__} {model.__name__} finished and stored')\n",
    "\n",
    "                finished_.append(pipeline_name)\n",
    "            else: \n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_preprocessed_data = ['gender_df_preprocessed_0', 'gender_df_preprocessed_1', \"gender_df_preprocessed_2\", 'gender_df_preprocessed_3', 'gender_df_preprocessed_4', 'gender_df_preprocessed_5', 'gender_df_preprocessed_6', 'gender_df_preprocessed_7', 'gender_df_preprocessed_9', 'gender_df_preprocessed_10', 'gender_df_preprocessed_11', 'gender_df_preprocessed_12', 'gender_df_preprocessed_13', 'gender_df_preprocessed_14', 'gender_df_preprocessed_15', 'gender_df_preprocessed_16', 'gender_df_preprocessed_17']\n",
    "list_of_vectorizers = [CountVectorizer]\n",
    "list_of_models = [RandomForestClassifier, LogisticRegression]\n",
    "\n",
    "\n",
    "# PIPELINES COBINATION AND IT'S SCORES FOR GENDER DATA\n",
    "df = pd.read_csv(r'scores.csv', names=['pipeline_name', 'pipeline_scores'])\n",
    "finished_ = df['pipeline_name'].tolist()\n",
    "\n",
    "file_path = r\"scores.csv\"\n",
    "\n",
    "for model in list_of_models:\n",
    "    for vectorizer in list_of_vectorizers:\n",
    "        for preprocessed_data in list_of_preprocessed_data:\n",
    "\n",
    "            pipeline_name = f\"pipeline_{preprocessed_data}_{vectorizer.__name__}_{model.__name__}\"\n",
    "\n",
    "            if pipeline_name not in finished_:\n",
    "                \n",
    "                \n",
    "                pipeline = Pipeline([\n",
    "                                    ('vectorizer', vectorizer()),\n",
    "                                    ('model', model())\n",
    "                                    ])\n",
    "\n",
    "                df = pd.read_json(rf'{path_to_data_folder}/{preprocessed_data}.json')\n",
    "\n",
    "                X = df[f'post'].tolist()\n",
    "                y = df[f'female'].tolist()\n",
    "\n",
    "                # Split the dataset into training and testing sets\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "                # fit the pipe\n",
    "                pipeline.fit(X_test, y_test)\n",
    "\n",
    "                # Predict on the test set\n",
    "                y_pred = pipeline.predict(X_test)\n",
    "\n",
    "                y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "                input_in_the_file = [pipeline_name, [f'Score: {pipeline.score(X_test, y_test)}', f'precision: {precision_score(y_test, y_pred)}', f'Recall: {recall_score(y_test, y_pred)}', f'ROC AUC: {roc_auc_score(y_test, y_pred_proba)}']]\n",
    "\n",
    "                # Append new data to the CSV file\n",
    "                with open(file_path, 'a', newline='') as csv_file:\n",
    "                    csv_writer = csv.writer(csv_file)\n",
    "                    csv_writer.writerow(input_in_the_file)\n",
    "\n",
    "                print(f'{preprocessed_data} {vectorizer.__name__} {model.__name__} finished and stored')\n",
    "\n",
    "                finished_.append(pipeline_name)\n",
    "            else: \n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_preprocessed_data = ['gender_df_preprocessed_0', 'gender_df_preprocessed_1', \"gender_df_preprocessed_2\", 'gender_df_preprocessed_3', 'gender_df_preprocessed_4', 'gender_df_preprocessed_5', 'gender_df_preprocessed_6', 'gender_df_preprocessed_7', 'gender_df_preprocessed_9', 'gender_df_preprocessed_10', 'gender_df_preprocessed_11', 'gender_df_preprocessed_12', 'gender_df_preprocessed_13', 'gender_df_preprocessed_14', 'gender_df_preprocessed_15', 'gender_df_preprocessed_16', 'gender_df_preprocessed_17']\n",
    "list_of_vectorizers = [Word2VecVectorizer]\n",
    "list_of_models = [RandomForestClassifier, LogisticRegression]\n",
    "\n",
    "\n",
    "# PIPELINES COBINATION AND IT'S SCORES FOR GENDER DATA\n",
    "df = pd.read_csv(r'scores.csv', names=['pipeline_name', 'pipeline_scores'])\n",
    "finished_ = df['pipeline_name'].tolist()\n",
    "\n",
    "file_path = r\"scores.csv\"\n",
    "\n",
    "for model in list_of_models:\n",
    "    for vectorizer in list_of_vectorizers:\n",
    "        for preprocessed_data in list_of_preprocessed_data:\n",
    "\n",
    "            pipeline_name = f\"pipeline_{preprocessed_data}_{vectorizer.name}_{model.name}\"\n",
    "\n",
    "            if pipeline_name not in finished_:\n",
    "                \n",
    "                \n",
    "                pipeline = Pipeline([\n",
    "                                    ('vectorizer', vectorizer(word2vec_model)),\n",
    "                                    ('model', model())\n",
    "                                    ])\n",
    "\n",
    "                df = pd.read_json(rf'{path_to_data_folder}/{preprocessed_data}.json')\n",
    "\n",
    "                X = df[f'post'].tolist()\n",
    "                y = df[f'female'].tolist()\n",
    "\n",
    "                # Split the dataset into training and testing sets\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "                # fi the pipe\n",
    "                pipeline.fit(X_train, y_train)\n",
    "\n",
    "                # Predict on the test set\n",
    "                y_pred = pipeline.predict(X_test)\n",
    "\n",
    "                y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "                input_in_the_file = [pipeline_name, [f'Score: {pipeline.score(X_test, y_test)}', f'precision: {precision_score(y_test, y_pred)}', f'Recall: {recall_score(y_test, y_pred)}', f'ROC AUC: {roc_auc_score(y_test, y_pred_proba)}']]\n",
    "\n",
    "                # Append new data to the CSV file\n",
    "                with open(file_path, 'a', newline='') as csv_file:\n",
    "                    csv_writer = csv.writer(csv_file)\n",
    "                    csv_writer.writerow(input_in_the_file)\n",
    "\n",
    "                print(f'{preprocessed_data} {vectorizer.name} {model.name} finished and stored')\n",
    "\n",
    "                finished_.append(pipeline_name)\n",
    "            else: \n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_preprocessed_data = ['gender_df_preprocessed_0', 'gender_df_preprocessed_1', \"gender_df_preprocessed_2\", 'gender_df_preprocessed_3', 'gender_df_preprocessed_4', 'gender_df_preprocessed_5', 'gender_df_preprocessed_6', 'gender_df_preprocessed_7', 'gender_df_preprocessed_9', 'gender_df_preprocessed_10', 'gender_df_preprocessed_11', 'gender_df_preprocessed_12', 'gender_df_preprocessed_13', 'gender_df_preprocessed_14', 'gender_df_preprocessed_15', 'gender_df_preprocessed_16', 'gender_df_preprocessed_17']\n",
    "list_of_vectorizers = [TfidfVectorizer, CountVectorizer, Word2VecVectorizer]\n",
    "list_of_models = [SVC]\n",
    "\n",
    "\n",
    "# PIPELINES COBINATION AND IT'S SCORES FOR GENDER DATA\n",
    "df = pd.read_csv(r'scores.csv', names=['pipeline_name', 'pipeline_scores'])\n",
    "finished_ = df['pipeline_name'].tolist()\n",
    "\n",
    "file_path = r\"scores.csv\"\n",
    "\n",
    "for model in list_of_models:\n",
    "    for vectorizer in list_of_vectorizers:\n",
    "        for preprocessed_data in list_of_preprocessed_data:\n",
    "\n",
    "            pipeline_name = f\"pipeline_{preprocessed_data}_{vectorizer.name}_{model.name}\"\n",
    "\n",
    "            if pipeline_name not in finished_:\n",
    "                \n",
    "                if vectorizer.name == 'Word2VecVectorizer':\n",
    "                        \n",
    "                    pipeline = Pipeline([\n",
    "                                        ('vectorizer', vectorizer(word2vec_model)),\n",
    "                                        ('model', OneVsRestClassifier(model(probability=True)))\n",
    "                                        ])\n",
    "            \n",
    "                else:\n",
    "                    pipeline = Pipeline([\n",
    "                                        ('vectorizer', vectorizer()),\n",
    "                                        ('model',OneVsRestClassifier(model(probability=True)))\n",
    "                                        ]) \n",
    "                df = pd.read_json(rf'C:/Users/marce/OneDrive/Desktop/lai_data/{preprocessed_data}.json')\n",
    "\n",
    "                X = df[f'post'].tolist()\n",
    "                y = df[f'female'].tolist()\n",
    "\n",
    "                # Split the dataset into training and testing sets\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "                # fi the pipe\n",
    "                pipeline.fit(X_train, y_train)\n",
    "\n",
    "                # Predict on the test set\n",
    "                y_pred = pipeline.predict(X_test)\n",
    "\n",
    "                probabilities = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "                input_in_the_file = [pipeline_name, [f'Score: {pipeline.score(X_test, y_test)}', \n",
    "                                                     f'precision: {precision_score(y_test, y_pred, average=\"micro\")}', \n",
    "                                                     f'Recall: {recall_score(y_test, y_pred, average=\"micro\")}', \n",
    "                                                     f'ROC AUC: {roc_auc_score(y_test, probabilities)}']]\n",
    "\n",
    "                # Append new data to the CSV file\n",
    "                with open(file_path, 'a', newline='') as csv_file:\n",
    "                    csv_writer = csv.writer(csv_file)\n",
    "                    csv_writer.writerow(input_in_the_file)\n",
    "\n",
    "                print(f'{preprocessed_data} {vectorizer.name} {model.name} finished and stored')\n",
    "\n",
    "                finished_.append(pipeline_name)\n",
    "            else: \n",
    "                continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

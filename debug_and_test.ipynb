{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/alexraudvee/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/alexraudvee/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dog be bark loudly outside .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Download WordNet data (needed for lemmatization) and punkt for normal functioning of tokinizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Lemmatize each word\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, pos=wordnet.VERB) for word in tokens]\n",
    "    \n",
    "    # Join lemmatized words back into a string\n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "    \n",
    "    return lemmatized_text\n",
    "\n",
    "# Example text\n",
    "text = \"The dogs are barking loudly outside.\"\n",
    "\n",
    "# Lemmatize the text\n",
    "lemmatized_text = lemmatize_text(text)\n",
    "print(lemmatized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed text with remove_stop_words: ['example', 'text', '.']\n",
      "Processed text with remove_upercase: ['this', 'is', 'an', 'example', 'text', '.']\n",
      "Processed text with remove_punctuation: ['This', 'is', 'an', 'example', 'text']\n",
      "Processed text with remove_stop_words -> remove_upercase: ['example', 'text', '.']\n",
      "Processed text with remove_stop_words -> remove_punctuation: ['example', 'text']\n",
      "Processed text with remove_upercase -> remove_punctuation: ['this', 'is', 'an', 'example', 'text']\n",
      "Processed text with remove_stop_words -> remove_upercase -> remove_punctuation: ['example', 'text']\n"
     ]
    }
   ],
   "source": [
    "from functions import tokenizer, remove_stop_words, remove_upercase, remove_punctuation\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Define your functions\n",
    "def function_1(text):\n",
    "    return text.upper()\n",
    "\n",
    "def function_2(text):\n",
    "    return text.lower()\n",
    "\n",
    "# Define more functions (function_3 to function_16) in a similar manner\n",
    "\n",
    "# Store your functions in a list\n",
    "function_list = [remove_stop_words, remove_upercase, remove_punctuation]  # Add all your functions here\n",
    "\n",
    "# Example text\n",
    "input_text = \"This is an example text.\"\n",
    "\n",
    "# Apply functions in parallel\n",
    "# Generate combinations of functions and apply them to the text\n",
    "for r in range(1, len(function_list) + 1):\n",
    "    for combination in itertools.combinations(function_list, r):\n",
    "        processed_text = input_text\n",
    "        for func in combination:\n",
    "            processed_text = func(processed_text)\n",
    "            \n",
    "        if type(processed_text) is str:\n",
    "            processed_text = tokenizer(processed_text)\n",
    "\n",
    "        print(f\"Processed text with {' -> '.join(f.__name__ for f in combination)}:\", processed_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: this is an example sentence .\n",
      "Bigrams: this_is an example sentence .\n",
      "Original Sentence: it demonstrates how to generate multi-word phrases using gensim library .\n",
      "Bigrams: it demonstrates how to generate multi-word phrases using gensim library .\n",
      "Original Sentence: this is another sentence for testing .\n",
      "Bigrams: this_is another sentence for testing .\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

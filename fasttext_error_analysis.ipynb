{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model performance analysis - fasttext\n",
    "\n",
    "This file is of more exploratory kind. It checks what kind of posts affect the missclassification of the model. In order to use it you need a pretrained model and a data set that would match chosen model. Unfortunately, in our case it is challenging to classify any patterns of speach that would affect the performence, because o the applied text preprocessing methods.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import fasttext\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading models\n",
    "\n",
    "model_path_14 = r\"fasttext_models\\model_raw\\model14.bin\"\n",
    "model_path_11 = r\"fasttext_models\\model_raw\\model11.bin\"\n",
    "model_14 =  fasttext.load_model(model_path_14)\n",
    "model_11 = fasttext.load_model(model_path_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data sets\n",
    "\n",
    "data_path_14 = r'data_preprocessed_df\\\\gender_df_preprocessed_14.json'\n",
    "df_14 = pd.read_json(data_path_14)\n",
    "\n",
    "data_path_11 = r'data_preprocessed_df\\\\gender_df_preprocessed_11.json'\n",
    "df_11 = pd.read_json(data_path_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 0\n",
    "# getting the data frames with target and predictors\n",
    "X_14 = df_14[df_14.columns[0]]\n",
    "y_14 = df_14[df_14.columns[1]]\n",
    "# splitting of the data for model14\n",
    "X_train_14, X_test_14, y_train_14, y_test_14 = train_test_split(X_14, y_14, test_size=0.2, random_state=seed_value)\n",
    "\n",
    "# getting the data frames with target and predictors\n",
    "X_11 = df_11[df_11.columns[0]]\n",
    "y_11 = df_11[df_11.columns[1]]\n",
    "# splitting of the data for model 11\n",
    "X_train_11, X_test_11, y_train_11, y_test_11 = train_test_split(X_11, y_11, test_size=0.2, random_state=seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pedicted_14 = [int(model_14.predict(text)[0][0][-1]) for text in X_test_14]\n",
    "y_predicted_11 = [int(model_11.predict(text)[0][0][-1]) for text in X_test_11]\n",
    "\n",
    "# connect pd.series to data frames\n",
    "df_test_14 = pd.concat([X_test_14, y_test_14], axis= 1)\n",
    "df_test_11 = pd.concat([X_test_11, y_test_11], axis= 1)\n",
    "\n",
    "df_test_14[\"predicted\"] = y_pedicted_14\n",
    "df_test_11[\"predicted\"] = y_predicted_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4268,  467],\n",
       "        [ 547, 3645]], dtype=int64),\n",
       " female\n",
       " 0    4735\n",
       " 1    4192\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets the confusion matrix for model 14\n",
    "conf_matrix_14 = confusion_matrix(df_test_14['female'], df_test_14[\"predicted\"])\n",
    "conf_matrix_14,df_test_14['female'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9013727560718057, 0.8695133587786259)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rate of classification for man and women for model 14, format: (man, woman)\n",
    "\n",
    "4268/4735, 3645/4192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4274,  461],\n",
       "        [ 559, 3633]], dtype=int64),\n",
       " female\n",
       " 0    4735\n",
       " 1    4192\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets the confusion matrix for model 11\n",
    "conf_matrix_11 = confusion_matrix(df_test_11['female'], df_test_11[\"predicted\"])\n",
    "conf_matrix_11, df_test_11['female'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9026399155227033, 0.8666507633587787)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rate of classification for man and women for model 11, format: (man, woman)\n",
    "4274/4735, 3633/4192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the probability of chosen label per post, there was an idea to check posts where the model missclasifies the most\n",
    "# this code work well with quick model like fasttext, it is not reccomneded to make such codes for more reasource consuming models\n",
    "df_test_11[\"probability\"] = df_test_11['post'].apply(lambda x: model_11.predict(x)[1][0])\n",
    "df_test_14[\"probability\"] = df_test_14['post'].apply(lambda x: model_14.predict(x)[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female\n",
       "1         80\n",
       "0         59\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating copy of main data frames, to see the distribution of given missclasifications\n",
    "\n",
    "x = df_test_11[df_test_11[\"female\"] != df_test_11[\"predicted\"]].sort_values(by='probability', ascending=False)\n",
    "x = x[(x['probability'] >= 0.90) & (x['probability'] <= 1)]\n",
    "x[['female']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving given data frame in order to get te\n",
    "x.to_csv(\"distribution_of_erros_model_11_range_0.9-1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
